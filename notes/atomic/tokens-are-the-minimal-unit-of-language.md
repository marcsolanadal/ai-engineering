# Tokens are the minimal unit of language
---

Tokens are used instead of words in LLMs since they're they are the building blocks of language.
As an example, we could invent a new word like ChatGPTing. Although this word doesn't exist we can understand what it means since we know ChatGPT and the +ing tense.
LLMs encode information in the same manner so they're more space efficient (they don't need to have words for garden, gardening, gardener) just with garden, +ing, & +er.

